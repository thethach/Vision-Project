{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were specific packets that were needed to run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T02:28:00.169487Z",
     "start_time": "2025-04-29T02:22:36.212448Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install opencv-python\n",
    "%pip install opencv-contrib-python\n",
    "%pip install opencv-python torch\n",
    "%pip install opencv-python ultralytics\n",
    "%pip install git+https://github.com/openai/CLIP.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:29:42.061843Z",
     "start_time": "2025-04-29T03:29:37.577652Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLOWorld\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1\" name=\"1\"></a>\n",
    "## **YOLO-World Model**\n",
    "The detect_objects function uses YOLO-World, a model that is open-vocabulary. Basically detecting any object that could be described with words, even if the model did not see it in the training. The PyTorch file that we are using is the yolov8x-worldv2. The \"v8x\" stands for the YOLOv8-Extra Large model. This model specificly is the most accurate but also the slowest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:29:45.853532Z",
     "start_time": "2025-04-29T03:29:45.839494Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect_objects(video_path, output_path, weight_file='yolov8x-worldv2.pt', classes=None, frame_skip=5, confidence_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Object Detection Pipeline using YOLO-World that saves annotated video.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video.\n",
    "        output_path (str): Path to save the annotated output video.\n",
    "        weight_file (str): Path to YOLO-World model weights.\n",
    "        classes (list of str): List of class names to detect.\n",
    "        frame_skip (int): Process every 'frame_skip' frames to save compute.\n",
    "        confidence_threshold (float): Minimum confidence to keep a detection.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = YOLOWorld(weight_file)\n",
    "\n",
    "    # Zero-shot detection\n",
    "    if classes is not None:\n",
    "        model.set_classes(classes)\n",
    "\n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open video\")\n",
    "\n",
    "    # Video writer setup\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps // frame_skip, (width, height))\n",
    "\n",
    "    frame_id = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "        # Skip frames if needed\n",
    "        if frame_id % frame_skip != 0:\n",
    "            continue\n",
    "\n",
    "        # Run detection\n",
    "        results = model.predict(frame)\n",
    "        boxes = results[0].boxes\n",
    "        predictions = boxes.data.cpu().numpy()\n",
    "\n",
    "        for pred in predictions:\n",
    "            x1, y1, x2, y2, score, class_id = pred[0], pred[1], pred[2], pred[3], pred[4], int(pred[5])\n",
    "\n",
    "            if score < confidence_threshold:\n",
    "                continue\n",
    "\n",
    "            label = f\"{model.names[class_id]} {score:.2f}\"\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "\n",
    "            # Draw label background\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            cv2.rectangle(frame, (int(x1), int(y1) - text_height - baseline), (int(x1) + text_width, int(y1)), color, -1)\n",
    "\n",
    "            # Draw label text\n",
    "            cv2.putText(frame, label, (int(x1), int(y1) - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the main function, we first specify the input video file path and create a new output video to save the annotated results. We then apply zero-shot object detection by providing the model with text prompts, allowing it to detect specified anomalies without additional training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:36:09.966972Z",
     "start_time": "2025-04-29T03:34:54.937278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 2 traffic lights, 41.4ms\n",
      "Speed: 2.2ms preprocess, 41.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 traffic light, 37.2ms\n",
      "Speed: 4.0ms preprocess, 37.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 traffic lights, 37.6ms\n",
      "Speed: 1.7ms preprocess, 37.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 2 traffic lights, 36.9ms\n",
      "Speed: 1.8ms preprocess, 36.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 traffic lights, 38.0ms\n",
      "Speed: 2.2ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 traffic light, 1 stop sign, 36.6ms\n",
      "Speed: 2.8ms preprocess, 36.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 2 traffic lights, 37.2ms\n",
      "Speed: 1.8ms preprocess, 37.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 2 traffic lights, 43.3ms\n",
      "Speed: 6.6ms preprocess, 43.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 2 traffic lights, 39.5ms\n",
      "Speed: 3.0ms preprocess, 39.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 2 traffic lights, 37.7ms\n",
      "Speed: 3.0ms preprocess, 37.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 2 traffic lights, 37.1ms\n",
      "Speed: 2.6ms preprocess, 37.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 2 traffic lights, 36.9ms\n",
      "Speed: 3.2ms preprocess, 36.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 1 car, 2 traffic lights, 1 stop sign, 39.2ms\n",
      "Speed: 3.5ms preprocess, 39.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 38.4ms\n",
      "Speed: 2.2ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 37.1ms\n",
      "Speed: 2.6ms preprocess, 37.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 bicycles, 1 car, 2 traffic lights, 38.7ms\n",
      "Speed: 2.8ms preprocess, 38.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 36.7ms\n",
      "Speed: 2.7ms preprocess, 36.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 36.8ms\n",
      "Speed: 2.8ms preprocess, 36.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 1 stop sign, 37.4ms\n",
      "Speed: 1.8ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 36.6ms\n",
      "Speed: 5.4ms preprocess, 36.6ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 traffic lights, 36.6ms\n",
      "Speed: 3.7ms preprocess, 36.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 1 car, 2 traffic lights, 37.0ms\n",
      "Speed: 3.1ms preprocess, 37.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 traffic lights, 36.1ms\n",
      "Speed: 1.8ms preprocess, 36.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 37.6ms\n",
      "Speed: 1.8ms preprocess, 37.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 traffic lights, 36.5ms\n",
      "Speed: 3.5ms preprocess, 36.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 40.1ms\n",
      "Speed: 2.3ms preprocess, 40.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 cars, 3 traffic lights, 1 stop sign, 43.4ms\n",
      "Speed: 4.0ms preprocess, 43.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 42.8ms\n",
      "Speed: 2.1ms preprocess, 42.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 43.7ms\n",
      "Speed: 1.9ms preprocess, 43.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 3 traffic lights, 44.3ms\n",
      "Speed: 2.7ms preprocess, 44.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 3 traffic lights, 43.4ms\n",
      "Speed: 2.7ms preprocess, 43.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 1 stop sign, 42.2ms\n",
      "Speed: 3.3ms preprocess, 42.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 1 car, 2 traffic lights, 43.7ms\n",
      "Speed: 3.9ms preprocess, 43.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 bicycles, 1 car, 2 traffic lights, 44.5ms\n",
      "Speed: 3.3ms preprocess, 44.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 1 car, 1 traffic light, 45.4ms\n",
      "Speed: 5.1ms preprocess, 45.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 traffic lights, 43.5ms\n",
      "Speed: 4.4ms preprocess, 43.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 2 cars, 2 traffic lights, 43.8ms\n",
      "Speed: 3.4ms preprocess, 43.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 2 cars, 2 traffic lights, 43.5ms\n",
      "Speed: 2.4ms preprocess, 43.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 2 cars, 2 traffic lights, 44.3ms\n",
      "Speed: 2.6ms preprocess, 44.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 3 traffic lights, 44.0ms\n",
      "Speed: 3.1ms preprocess, 44.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 1 car, 2 traffic lights, 43.6ms\n",
      "Speed: 2.9ms preprocess, 43.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 2 cars, 2 traffic lights, 43.2ms\n",
      "Speed: 1.7ms preprocess, 43.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 2 cars, 1 traffic light, 44.9ms\n",
      "Speed: 3.2ms preprocess, 44.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 traffic light, 42.3ms\n",
      "Speed: 3.3ms preprocess, 42.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 2 cars, 2 traffic lights, 45.2ms\n",
      "Speed: 4.5ms preprocess, 45.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 1 car, 1 traffic light, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 43.3ms\n",
      "Speed: 2.8ms preprocess, 43.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 1 traffic light, 43.9ms\n",
      "Speed: 1.8ms preprocess, 43.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 1 traffic light, 43.6ms\n",
      "Speed: 1.9ms preprocess, 43.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 1 traffic light, 56.3ms\n",
      "Speed: 2.4ms preprocess, 56.3ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 bicycles, 1 traffic light, 42.5ms\n",
      "Speed: 2.1ms preprocess, 42.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 motorcycle, 1 traffic light, 44.3ms\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 bicycles, 1 motorcycle, 1 traffic light, 43.2ms\n",
      "Speed: 3.4ms preprocess, 43.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 bicycles, 1 traffic light, 46.0ms\n",
      "Speed: 2.3ms preprocess, 46.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 bicycles, 1 traffic light, 43.7ms\n",
      "Speed: 2.9ms preprocess, 43.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 bicycles, 42.9ms\n",
      "Speed: 1.9ms preprocess, 42.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 bicycles, 1 traffic light, 42.5ms\n",
      "Speed: 2.5ms preprocess, 42.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 bicycles, 2 traffic lights, 44.5ms\n",
      "Speed: 3.4ms preprocess, 44.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 bicycles, 2 traffic lights, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 bicycles, 2 traffic lights, 45.1ms\n",
      "Speed: 2.6ms preprocess, 45.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 bicycles, 1 car, 1 traffic light, 44.1ms\n",
      "Speed: 3.2ms preprocess, 44.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 bicycles, 2 cars, 2 traffic lights, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 bicycles, 2 cars, 3 traffic lights, 45.1ms\n",
      "Speed: 3.3ms preprocess, 45.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 bicycles, 2 cars, 2 traffic lights, 43.1ms\n",
      "Speed: 2.7ms preprocess, 43.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 bicycles, 1 car, 2 traffic lights, 43.4ms\n",
      "Speed: 2.0ms preprocess, 43.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 bicycles, 1 car, 2 traffic lights, 43.0ms\n",
      "Speed: 2.7ms preprocess, 43.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 bicycles, 1 car, 2 traffic lights, 44.6ms\n",
      "Speed: 6.6ms preprocess, 44.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 1 car, 2 traffic lights, 43.8ms\n",
      "Speed: 2.9ms preprocess, 43.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 2 cars, 2 traffic lights, 43.4ms\n",
      "Speed: 3.5ms preprocess, 43.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 1 car, 3 traffic lights, 45.4ms\n",
      "Speed: 2.5ms preprocess, 45.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 1 car, 4 traffic lights, 44.1ms\n",
      "Speed: 3.4ms preprocess, 44.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 1 car, 3 traffic lights, 43.9ms\n",
      "Speed: 5.7ms preprocess, 43.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 1 car, 3 traffic lights, 1 stop sign, 43.2ms\n",
      "Speed: 3.0ms preprocess, 43.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 2 traffic lights, 47.0ms\n",
      "Speed: 2.5ms preprocess, 47.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 2 traffic lights, 43.1ms\n",
      "Speed: 2.3ms preprocess, 43.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 2 traffic lights, 45.4ms\n",
      "Speed: 2.5ms preprocess, 45.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 3 traffic lights, 45.5ms\n",
      "Speed: 2.9ms preprocess, 45.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 2 traffic lights, 42.7ms\n",
      "Speed: 2.4ms preprocess, 42.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 2 traffic lights, 46.4ms\n",
      "Speed: 3.7ms preprocess, 46.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 3 traffic lights, 45.3ms\n",
      "Speed: 2.6ms preprocess, 45.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 2 traffic lights, 48.6ms\n",
      "Speed: 2.4ms preprocess, 48.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 49.4ms\n",
      "Speed: 1.9ms preprocess, 49.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 47.7ms\n",
      "Speed: 2.4ms preprocess, 47.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 3 traffic lights, 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 3 traffic lights, 48.6ms\n",
      "Speed: 3.1ms preprocess, 48.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 47.3ms\n",
      "Speed: 3.6ms preprocess, 47.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 1 stop sign, 44.1ms\n",
      "Speed: 1.9ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 1 stop sign, 48.0ms\n",
      "Speed: 2.7ms preprocess, 48.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 1 stop sign, 49.3ms\n",
      "Speed: 4.3ms preprocess, 49.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 traffic light, 50.5ms\n",
      "Speed: 2.0ms preprocess, 50.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 traffic light, 1 stop sign, 50.1ms\n",
      "Speed: 1.8ms preprocess, 50.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 traffic light, 47.9ms\n",
      "Speed: 1.7ms preprocess, 47.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 traffic light, 48.5ms\n",
      "Speed: 1.9ms preprocess, 48.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 traffic light, 1 stop sign, 46.8ms\n",
      "Speed: 1.9ms preprocess, 46.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 traffic light, 1 stop sign, 49.2ms\n",
      "Speed: 2.6ms preprocess, 49.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 stop sign, 49.4ms\n",
      "Speed: 2.4ms preprocess, 49.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 traffic light, 1 stop sign, 45.9ms\n",
      "Speed: 2.4ms preprocess, 45.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 47.0ms\n",
      "Speed: 1.7ms preprocess, 47.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 traffic lights, 1 stop sign, 47.6ms\n",
      "Speed: 2.4ms preprocess, 47.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 47.8ms\n",
      "Speed: 2.6ms preprocess, 47.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 48.4ms\n",
      "Speed: 2.3ms preprocess, 48.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 traffic lights, 48.4ms\n",
      "Speed: 14.2ms preprocess, 48.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 traffic lights, 46.9ms\n",
      "Speed: 1.8ms preprocess, 46.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 traffic lights, 1 stop sign, 48.7ms\n",
      "Speed: 2.6ms preprocess, 48.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 47.0ms\n",
      "Speed: 1.9ms preprocess, 47.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 stop sign, 46.1ms\n",
      "Speed: 2.2ms preprocess, 46.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 2 stop signs, 46.8ms\n",
      "Speed: 2.7ms preprocess, 46.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 stop signs, 49.0ms\n",
      "Speed: 4.0ms preprocess, 49.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 stop sign, 45.5ms\n",
      "Speed: 2.7ms preprocess, 45.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 stop sign, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 stop sign, 46.9ms\n",
      "Speed: 5.8ms preprocess, 46.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 3 stop signs, 48.2ms\n",
      "Speed: 3.3ms preprocess, 48.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 traffic light, 1 stop sign, 48.5ms\n",
      "Speed: 3.4ms preprocess, 48.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 stop signs, 46.4ms\n",
      "Speed: 3.0ms preprocess, 46.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 46.2ms\n",
      "Speed: 2.5ms preprocess, 46.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 stop sign, 47.5ms\n",
      "Speed: 2.8ms preprocess, 47.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 stop signs, 48.4ms\n",
      "Speed: 1.7ms preprocess, 48.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 stop sign, 46.6ms\n",
      "Speed: 1.9ms preprocess, 46.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 2 stop signs, 46.2ms\n",
      "Speed: 2.3ms preprocess, 46.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 stop signs, 47.8ms\n",
      "Speed: 2.8ms preprocess, 47.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 stop signs, 47.6ms\n",
      "Speed: 1.7ms preprocess, 47.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 2 stop signs, 49.0ms\n",
      "Speed: 3.1ms preprocess, 49.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 2 stop signs, 49.7ms\n",
      "Speed: 2.3ms preprocess, 49.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 stop signs, 46.9ms\n",
      "Speed: 2.5ms preprocess, 46.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 stop signs, 45.2ms\n",
      "Speed: 1.8ms preprocess, 45.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 47.1ms\n",
      "Speed: 1.8ms preprocess, 47.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 48.2ms\n",
      "Speed: 1.8ms preprocess, 48.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 48.7ms\n",
      "Speed: 2.5ms preprocess, 48.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 48.3ms\n",
      "Speed: 3.6ms preprocess, 48.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 47.3ms\n",
      "Speed: 3.1ms preprocess, 47.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 46.7ms\n",
      "Speed: 1.9ms preprocess, 46.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 stop sign, 46.0ms\n",
      "Speed: 2.1ms preprocess, 46.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 2 stop signs, 46.0ms\n",
      "Speed: 3.9ms preprocess, 46.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 stop signs, 50.6ms\n",
      "Speed: 2.0ms preprocess, 50.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 1 stop sign, 48.4ms\n",
      "Speed: 4.8ms preprocess, 48.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 2 stop signs, 46.7ms\n",
      "Speed: 1.9ms preprocess, 46.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 2 stop signs, 46.1ms\n",
      "Speed: 3.0ms preprocess, 46.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 stop signs, 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 traffic light, 1 stop sign, 49.7ms\n",
      "Speed: 1.7ms preprocess, 49.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 bicycles, 1 traffic light, 1 stop sign, 46.7ms\n",
      "Speed: 2.6ms preprocess, 46.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 1 traffic light, 2 stop signs, 46.5ms\n",
      "Speed: 2.2ms preprocess, 46.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 traffic light, 2 stop signs, 48.8ms\n",
      "Speed: 5.1ms preprocess, 48.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 2 traffic lights, 2 stop signs, 48.0ms\n",
      "Speed: 3.3ms preprocess, 48.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 46.5ms\n",
      "Speed: 1.8ms preprocess, 46.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 1 traffic light, 2 stop signs, 48.7ms\n",
      "Speed: 2.1ms preprocess, 48.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 48.1ms\n",
      "Speed: 2.6ms preprocess, 48.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 1 stop sign, 48.6ms\n",
      "Speed: 3.5ms preprocess, 48.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 traffic light, 2 stop signs, 45.4ms\n",
      "Speed: 2.8ms preprocess, 45.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 traffic light, 1 stop sign, 47.5ms\n",
      "Speed: 3.9ms preprocess, 47.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 traffic light, 1 stop sign, 47.7ms\n",
      "Speed: 2.1ms preprocess, 47.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 traffic light, 1 stop sign, 46.6ms\n",
      "Speed: 2.6ms preprocess, 46.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 traffic light, 1 stop sign, 46.6ms\n",
      "Speed: 2.9ms preprocess, 46.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 2 stop signs, 62.2ms\n",
      "Speed: 3.8ms preprocess, 62.2ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 2 stop signs, 48.1ms\n",
      "Speed: 2.4ms preprocess, 48.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 traffic light, 2 stop signs, 44.5ms\n",
      "Speed: 3.2ms preprocess, 44.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 traffic light, 2 stop signs, 43.7ms\n",
      "Speed: 2.0ms preprocess, 43.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 traffic lights, 1 stop sign, 47.0ms\n",
      "Speed: 3.1ms preprocess, 47.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 3 cars, 1 traffic light, 2 stop signs, 48.1ms\n",
      "Speed: 2.4ms preprocess, 48.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 3 cars, 1 traffic light, 2 stop signs, 48.6ms\n",
      "Speed: 5.6ms preprocess, 48.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 1 traffic light, 2 stop signs, 45.3ms\n",
      "Speed: 2.3ms preprocess, 45.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 2 stop signs, 45.7ms\n",
      "Speed: 2.8ms preprocess, 45.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 1 traffic light, 2 stop signs, 52.5ms\n",
      "Speed: 3.0ms preprocess, 52.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 2 stop signs, 47.3ms\n",
      "Speed: 3.7ms preprocess, 47.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 2 stop signs, 46.1ms\n",
      "Speed: 3.0ms preprocess, 46.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 2 stop signs, 48.0ms\n",
      "Speed: 2.2ms preprocess, 48.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 1 traffic light, 2 stop signs, 52.3ms\n",
      "Speed: 10.0ms preprocess, 52.3ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 1 traffic light, 2 stop signs, 51.6ms\n",
      "Speed: 3.1ms preprocess, 51.6ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 2 traffic lights, 2 stop signs, 55.3ms\n",
      "Speed: 2.6ms preprocess, 55.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 2 cars, 2 traffic lights, 2 stop signs, 56.8ms\n",
      "Speed: 2.7ms preprocess, 56.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 2 traffic lights, 2 stop signs, 52.4ms\n",
      "Speed: 1.8ms preprocess, 52.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 2 traffic lights, 1 stop sign, 53.5ms\n",
      "Speed: 3.5ms preprocess, 53.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 traffic lights, 1 stop sign, 55.5ms\n",
      "Speed: 1.8ms preprocess, 55.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 traffic lights, 1 stop sign, 48.6ms\n",
      "Speed: 2.4ms preprocess, 48.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 traffic lights, 1 stop sign, 47.3ms\n",
      "Speed: 1.8ms preprocess, 47.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 1 traffic light, 1 stop sign, 46.9ms\n",
      "Speed: 2.2ms preprocess, 46.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 3 traffic lights, 1 stop sign, 46.0ms\n",
      "Speed: 2.0ms preprocess, 46.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 3 traffic lights, 1 stop sign, 48.2ms\n",
      "Speed: 2.3ms preprocess, 48.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 3 traffic lights, 1 stop sign, 49.6ms\n",
      "Speed: 2.1ms preprocess, 49.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 1 stop sign, 47.4ms\n",
      "Speed: 2.2ms preprocess, 47.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 1 traffic light, 1 stop sign, 45.8ms\n",
      "Speed: 1.9ms preprocess, 45.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 stop sign, 46.2ms\n",
      "Speed: 1.8ms preprocess, 46.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 1 stop sign, 47.0ms\n",
      "Speed: 2.3ms preprocess, 47.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 traffic lights, 1 stop sign, 46.5ms\n",
      "Speed: 1.7ms preprocess, 46.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 47.2ms\n",
      "Speed: 1.7ms preprocess, 47.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 stop sign, 45.7ms\n",
      "Speed: 1.9ms preprocess, 45.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 49.8ms\n",
      "Speed: 2.3ms preprocess, 49.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 48.0ms\n",
      "Speed: 2.1ms preprocess, 48.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 stop sign, 48.0ms\n",
      "Speed: 2.3ms preprocess, 48.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 47.9ms\n",
      "Speed: 3.4ms preprocess, 47.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 stop sign, 48.8ms\n",
      "Speed: 1.8ms preprocess, 48.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 1 stop sign, 48.1ms\n",
      "Speed: 1.9ms preprocess, 48.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Video saved\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    video_file = r\"C:\\Users\\tyler\\OneDrive\\Desktop\\Computer Vision\\CV Project\\Videos\\walkog.mp4\"\n",
    "    output_video_file = r\"C:\\Users\\tyler\\OneDrive\\Desktop\\Computer Vision\\CV Project\\Videos\\LLM_walk.mp4\"\n",
    "\n",
    "    walking_hazards = [\n",
    "        'person', 'bicycle', 'car', 'motorcycle', 'bus', 'truck', 'traffic light', 'stop sign'\n",
    "    ]\n",
    "\n",
    "    detect_objects(video_file, output_video_file, classes=walking_hazards)\n",
    "    print(\"Video saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code processes the entire video and generates a single scene description at the end.\n",
    "It does not provide real-time descriptions or warnings.\n",
    "The object detection is performed frame-by-frame, but only one final description is produced after processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T04:34:46.438472Z",
     "start_time": "2025-04-29T04:33:34.330913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 2 traffic lights, 41.7ms\n",
      "Speed: 3.1ms preprocess, 41.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 traffic light, 36.6ms\n",
      "Speed: 1.8ms preprocess, 36.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 traffic lights, 37.7ms\n",
      "Speed: 3.8ms preprocess, 37.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 2 traffic lights, 36.8ms\n",
      "Speed: 3.3ms preprocess, 36.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 traffic lights, 37.0ms\n",
      "Speed: 2.7ms preprocess, 37.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 traffic light, 1 stop sign, 37.7ms\n",
      "Speed: 2.9ms preprocess, 37.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 2 traffic lights, 37.1ms\n",
      "Speed: 2.2ms preprocess, 37.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 2 traffic lights, 36.4ms\n",
      "Speed: 1.8ms preprocess, 36.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 2 traffic lights, 36.7ms\n",
      "Speed: 1.7ms preprocess, 36.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 2 traffic lights, 38.1ms\n",
      "Speed: 3.0ms preprocess, 38.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 2 traffic lights, 36.5ms\n",
      "Speed: 3.2ms preprocess, 36.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 2 traffic lights, 38.5ms\n",
      "Speed: 1.8ms preprocess, 38.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 1 car, 2 traffic lights, 1 stop sign, 38.5ms\n",
      "Speed: 1.9ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 36.8ms\n",
      "Speed: 2.0ms preprocess, 36.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 37.4ms\n",
      "Speed: 2.6ms preprocess, 37.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 bicycles, 1 car, 2 traffic lights, 38.2ms\n",
      "Speed: 1.8ms preprocess, 38.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 37.0ms\n",
      "Speed: 2.8ms preprocess, 37.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 1 stop sign, 37.7ms\n",
      "Speed: 1.7ms preprocess, 37.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 37.1ms\n",
      "Speed: 1.8ms preprocess, 37.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 traffic lights, 41.7ms\n",
      "Speed: 1.9ms preprocess, 41.7ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 1 car, 2 traffic lights, 42.0ms\n",
      "Speed: 3.4ms preprocess, 42.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 traffic lights, 38.3ms\n",
      "Speed: 2.4ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 37.3ms\n",
      "Speed: 1.8ms preprocess, 37.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 traffic lights, 40.8ms\n",
      "Speed: 6.5ms preprocess, 40.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 37.6ms\n",
      "Speed: 1.7ms preprocess, 37.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 cars, 3 traffic lights, 1 stop sign, 38.4ms\n",
      "Speed: 3.1ms preprocess, 38.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 37.0ms\n",
      "Speed: 3.6ms preprocess, 37.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 38.3ms\n",
      "Speed: 4.1ms preprocess, 38.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 3 traffic lights, 36.7ms\n",
      "Speed: 1.7ms preprocess, 36.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 3 traffic lights, 36.4ms\n",
      "Speed: 1.7ms preprocess, 36.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 1 stop sign, 39.2ms\n",
      "Speed: 5.6ms preprocess, 39.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 1 car, 2 traffic lights, 37.4ms\n",
      "Speed: 2.4ms preprocess, 37.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 bicycles, 1 car, 2 traffic lights, 36.3ms\n",
      "Speed: 2.1ms preprocess, 36.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 1 car, 1 traffic light, 37.8ms\n",
      "Speed: 2.2ms preprocess, 37.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 traffic lights, 36.4ms\n",
      "Speed: 3.6ms preprocess, 36.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 2 cars, 2 traffic lights, 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 2 cars, 2 traffic lights, 36.8ms\n",
      "Speed: 2.3ms preprocess, 36.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 2 cars, 2 traffic lights, 36.5ms\n",
      "Speed: 2.3ms preprocess, 36.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 3 traffic lights, 38.1ms\n",
      "Speed: 2.5ms preprocess, 38.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 1 car, 2 traffic lights, 36.3ms\n",
      "Speed: 2.6ms preprocess, 36.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 2 cars, 2 traffic lights, 34.9ms\n",
      "Speed: 2.4ms preprocess, 34.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 2 cars, 1 traffic light, 39.4ms\n",
      "Speed: 4.3ms preprocess, 39.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 traffic light, 38.1ms\n",
      "Speed: 3.6ms preprocess, 38.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 2 cars, 2 traffic lights, 37.0ms\n",
      "Speed: 2.5ms preprocess, 37.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 1 car, 1 traffic light, 37.0ms\n",
      "Speed: 2.6ms preprocess, 37.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 36.4ms\n",
      "Speed: 1.9ms preprocess, 36.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 1 traffic light, 38.3ms\n",
      "Speed: 1.7ms preprocess, 38.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 1 car, 1 traffic light, 36.9ms\n",
      "Speed: 2.6ms preprocess, 36.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 car, 1 traffic light, 42.5ms\n",
      "Speed: 1.8ms preprocess, 42.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 bicycles, 1 traffic light, 45.4ms\n",
      "Speed: 3.8ms preprocess, 45.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bicycle, 1 motorcycle, 1 traffic light, 42.9ms\n",
      "Speed: 2.0ms preprocess, 42.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 bicycles, 1 motorcycle, 1 traffic light, 43.3ms\n",
      "Speed: 2.1ms preprocess, 43.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 bicycles, 1 traffic light, 43.9ms\n",
      "Speed: 2.6ms preprocess, 43.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 bicycles, 1 traffic light, 44.6ms\n",
      "Speed: 3.0ms preprocess, 44.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 bicycles, 44.2ms\n",
      "Speed: 3.0ms preprocess, 44.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 bicycles, 1 traffic light, 43.0ms\n",
      "Speed: 3.2ms preprocess, 43.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 bicycles, 2 traffic lights, 45.3ms\n",
      "Speed: 1.8ms preprocess, 45.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 bicycles, 2 traffic lights, 42.8ms\n",
      "Speed: 3.7ms preprocess, 42.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 bicycles, 2 traffic lights, 43.2ms\n",
      "Speed: 2.9ms preprocess, 43.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 bicycles, 1 car, 1 traffic light, 42.7ms\n",
      "Speed: 2.3ms preprocess, 42.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 bicycles, 2 cars, 2 traffic lights, 42.0ms\n",
      "Speed: 3.0ms preprocess, 42.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 bicycles, 2 cars, 3 traffic lights, 43.6ms\n",
      "Speed: 2.1ms preprocess, 43.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 bicycles, 2 cars, 2 traffic lights, 41.7ms\n",
      "Speed: 2.3ms preprocess, 41.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 bicycles, 1 car, 2 traffic lights, 43.6ms\n",
      "Speed: 3.0ms preprocess, 43.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 bicycles, 1 car, 2 traffic lights, 42.3ms\n",
      "Speed: 1.7ms preprocess, 42.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 bicycles, 1 car, 2 traffic lights, 43.6ms\n",
      "Speed: 2.2ms preprocess, 43.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 1 car, 2 traffic lights, 42.9ms\n",
      "Speed: 1.7ms preprocess, 42.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 2 cars, 2 traffic lights, 40.6ms\n",
      "Speed: 2.1ms preprocess, 40.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 1 car, 3 traffic lights, 40.2ms\n",
      "Speed: 1.8ms preprocess, 40.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 1 car, 4 traffic lights, 41.8ms\n",
      "Speed: 1.8ms preprocess, 41.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 1 car, 3 traffic lights, 44.2ms\n",
      "Speed: 2.8ms preprocess, 44.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 1 car, 3 traffic lights, 1 stop sign, 43.1ms\n",
      "Speed: 4.8ms preprocess, 43.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 2 traffic lights, 45.7ms\n",
      "Speed: 2.6ms preprocess, 45.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 2 traffic lights, 45.9ms\n",
      "Speed: 2.8ms preprocess, 45.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 2 traffic lights, 47.3ms\n",
      "Speed: 3.2ms preprocess, 47.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 3 traffic lights, 45.8ms\n",
      "Speed: 2.5ms preprocess, 45.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 2 traffic lights, 49.4ms\n",
      "Speed: 4.7ms preprocess, 49.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 2 traffic lights, 53.7ms\n",
      "Speed: 2.6ms preprocess, 53.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 3 traffic lights, 47.6ms\n",
      "Speed: 1.9ms preprocess, 47.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 2 traffic lights, 46.1ms\n",
      "Speed: 2.8ms preprocess, 46.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 49.3ms\n",
      "Speed: 3.7ms preprocess, 49.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 47.2ms\n",
      "Speed: 2.5ms preprocess, 47.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 3 traffic lights, 48.6ms\n",
      "Speed: 1.8ms preprocess, 48.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 3 traffic lights, 49.1ms\n",
      "Speed: 2.7ms preprocess, 49.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 45.7ms\n",
      "Speed: 2.8ms preprocess, 45.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 1 stop sign, 85.1ms\n",
      "Speed: 4.9ms preprocess, 85.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 1 stop sign, 47.4ms\n",
      "Speed: 2.4ms preprocess, 47.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 1 stop sign, 49.2ms\n",
      "Speed: 3.4ms preprocess, 49.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 traffic light, 48.1ms\n",
      "Speed: 4.1ms preprocess, 48.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 traffic light, 1 stop sign, 44.9ms\n",
      "Speed: 3.0ms preprocess, 44.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 traffic light, 45.9ms\n",
      "Speed: 1.8ms preprocess, 45.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 traffic light, 45.5ms\n",
      "Speed: 2.0ms preprocess, 45.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 traffic light, 1 stop sign, 45.3ms\n",
      "Speed: 2.1ms preprocess, 45.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 traffic light, 1 stop sign, 45.7ms\n",
      "Speed: 3.6ms preprocess, 45.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 stop sign, 47.4ms\n",
      "Speed: 5.2ms preprocess, 47.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 traffic light, 1 stop sign, 48.3ms\n",
      "Speed: 2.5ms preprocess, 48.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 46.0ms\n",
      "Speed: 1.9ms preprocess, 46.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 47.1ms\n",
      "Speed: 1.7ms preprocess, 47.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 traffic lights, 1 stop sign, 47.9ms\n",
      "Speed: 1.9ms preprocess, 47.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 46.9ms\n",
      "Speed: 2.8ms preprocess, 46.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 46.9ms\n",
      "Speed: 1.8ms preprocess, 46.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 traffic lights, 46.4ms\n",
      "Speed: 2.2ms preprocess, 46.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 traffic lights, 48.9ms\n",
      "Speed: 2.0ms preprocess, 48.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 traffic lights, 1 stop sign, 46.5ms\n",
      "Speed: 2.4ms preprocess, 46.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 45.9ms\n",
      "Speed: 2.1ms preprocess, 45.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 stop sign, 46.7ms\n",
      "Speed: 1.8ms preprocess, 46.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 2 stop signs, 52.7ms\n",
      "Speed: 3.0ms preprocess, 52.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 stop signs, 49.9ms\n",
      "Speed: 2.5ms preprocess, 49.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 stop sign, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 stop sign, 52.1ms\n",
      "Speed: 2.3ms preprocess, 52.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 stop sign, 50.4ms\n",
      "Speed: 2.8ms preprocess, 50.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 3 stop signs, 49.4ms\n",
      "Speed: 2.0ms preprocess, 49.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 traffic light, 1 stop sign, 53.4ms\n",
      "Speed: 3.0ms preprocess, 53.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 stop signs, 54.0ms\n",
      "Speed: 2.1ms preprocess, 54.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 53.9ms\n",
      "Speed: 2.3ms preprocess, 53.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 stop sign, 52.4ms\n",
      "Speed: 2.0ms preprocess, 52.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 stop signs, 50.7ms\n",
      "Speed: 2.3ms preprocess, 50.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 stop sign, 53.7ms\n",
      "Speed: 3.1ms preprocess, 53.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 2 stop signs, 50.9ms\n",
      "Speed: 2.5ms preprocess, 50.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 stop signs, 52.1ms\n",
      "Speed: 3.1ms preprocess, 52.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 stop signs, 51.4ms\n",
      "Speed: 4.2ms preprocess, 51.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 2 stop signs, 50.4ms\n",
      "Speed: 1.8ms preprocess, 50.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 traffic lights, 2 stop signs, 50.8ms\n",
      "Speed: 2.8ms preprocess, 50.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 stop signs, 49.9ms\n",
      "Speed: 2.3ms preprocess, 49.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 stop signs, 49.8ms\n",
      "Speed: 2.0ms preprocess, 49.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 52.9ms\n",
      "Speed: 3.1ms preprocess, 52.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 50.4ms\n",
      "Speed: 5.6ms preprocess, 50.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 50.3ms\n",
      "Speed: 1.9ms preprocess, 50.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 51.5ms\n",
      "Speed: 3.0ms preprocess, 51.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 48.1ms\n",
      "Speed: 1.9ms preprocess, 48.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 49.9ms\n",
      "Speed: 1.8ms preprocess, 49.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 1 stop sign, 53.4ms\n",
      "Speed: 2.1ms preprocess, 53.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 2 stop signs, 46.0ms\n",
      "Speed: 2.7ms preprocess, 46.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 stop signs, 45.5ms\n",
      "Speed: 2.5ms preprocess, 45.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 1 stop sign, 45.8ms\n",
      "Speed: 2.6ms preprocess, 45.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 traffic light, 2 stop signs, 48.3ms\n",
      "Speed: 1.8ms preprocess, 48.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 2 stop signs, 47.0ms\n",
      "Speed: 2.7ms preprocess, 47.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 stop signs, 45.4ms\n",
      "Speed: 2.4ms preprocess, 45.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 traffic light, 1 stop sign, 47.6ms\n",
      "Speed: 1.8ms preprocess, 47.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 bicycles, 1 traffic light, 1 stop sign, 48.7ms\n",
      "Speed: 2.2ms preprocess, 48.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 1 traffic light, 2 stop signs, 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 traffic light, 2 stop signs, 45.4ms\n",
      "Speed: 2.5ms preprocess, 45.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 2 traffic lights, 2 stop signs, 44.8ms\n",
      "Speed: 2.4ms preprocess, 44.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 46.2ms\n",
      "Speed: 1.9ms preprocess, 46.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 1 traffic light, 2 stop signs, 45.5ms\n",
      "Speed: 1.8ms preprocess, 45.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 46.6ms\n",
      "Speed: 2.8ms preprocess, 46.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 1 stop sign, 46.0ms\n",
      "Speed: 1.8ms preprocess, 46.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 traffic light, 2 stop signs, 48.3ms\n",
      "Speed: 3.9ms preprocess, 48.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 traffic light, 1 stop sign, 50.5ms\n",
      "Speed: 2.1ms preprocess, 50.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 traffic light, 1 stop sign, 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 traffic light, 1 stop sign, 45.0ms\n",
      "Speed: 3.0ms preprocess, 45.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 traffic light, 1 stop sign, 47.8ms\n",
      "Speed: 1.8ms preprocess, 47.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 2 stop signs, 47.7ms\n",
      "Speed: 3.1ms preprocess, 47.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 2 stop signs, 46.7ms\n",
      "Speed: 2.9ms preprocess, 46.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 traffic light, 2 stop signs, 46.6ms\n",
      "Speed: 1.7ms preprocess, 46.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 traffic light, 2 stop signs, 45.7ms\n",
      "Speed: 1.9ms preprocess, 45.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 traffic lights, 1 stop sign, 46.3ms\n",
      "Speed: 1.8ms preprocess, 46.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 3 cars, 1 traffic light, 2 stop signs, 46.8ms\n",
      "Speed: 2.6ms preprocess, 46.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 3 cars, 1 traffic light, 2 stop signs, 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 1 traffic light, 2 stop signs, 46.4ms\n",
      "Speed: 1.9ms preprocess, 46.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 2 stop signs, 46.8ms\n",
      "Speed: 1.7ms preprocess, 46.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 1 traffic light, 2 stop signs, 45.4ms\n",
      "Speed: 1.8ms preprocess, 45.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 2 stop signs, 45.8ms\n",
      "Speed: 1.9ms preprocess, 45.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 2 stop signs, 48.1ms\n",
      "Speed: 1.8ms preprocess, 48.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 2 stop signs, 46.8ms\n",
      "Speed: 1.9ms preprocess, 46.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 1 traffic light, 2 stop signs, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 1 traffic light, 2 stop signs, 48.4ms\n",
      "Speed: 1.9ms preprocess, 48.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 2 traffic lights, 2 stop signs, 45.6ms\n",
      "Speed: 1.9ms preprocess, 45.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 2 cars, 2 traffic lights, 2 stop signs, 46.2ms\n",
      "Speed: 2.2ms preprocess, 46.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 2 traffic lights, 2 stop signs, 44.8ms\n",
      "Speed: 1.8ms preprocess, 44.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 2 traffic lights, 1 stop sign, 48.1ms\n",
      "Speed: 2.2ms preprocess, 48.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 traffic lights, 1 stop sign, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 traffic lights, 1 stop sign, 45.6ms\n",
      "Speed: 2.4ms preprocess, 45.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 traffic lights, 1 stop sign, 48.5ms\n",
      "Speed: 1.8ms preprocess, 48.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 1 traffic light, 1 stop sign, 46.6ms\n",
      "Speed: 2.7ms preprocess, 46.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 1 car, 3 traffic lights, 1 stop sign, 45.1ms\n",
      "Speed: 2.8ms preprocess, 45.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 3 traffic lights, 1 stop sign, 45.7ms\n",
      "Speed: 3.0ms preprocess, 45.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 3 traffic lights, 1 stop sign, 45.0ms\n",
      "Speed: 2.8ms preprocess, 45.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 1 stop sign, 46.6ms\n",
      "Speed: 1.7ms preprocess, 46.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 1 traffic light, 1 stop sign, 44.8ms\n",
      "Speed: 3.1ms preprocess, 44.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 stop sign, 44.6ms\n",
      "Speed: 3.1ms preprocess, 44.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 traffic light, 1 stop sign, 48.4ms\n",
      "Speed: 2.3ms preprocess, 48.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 traffic lights, 1 stop sign, 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 47.5ms\n",
      "Speed: 3.1ms preprocess, 47.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 stop sign, 47.8ms\n",
      "Speed: 2.5ms preprocess, 47.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 45.3ms\n",
      "Speed: 2.5ms preprocess, 45.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 46.3ms\n",
      "Speed: 3.5ms preprocess, 46.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 stop sign, 46.5ms\n",
      "Speed: 1.7ms preprocess, 46.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 traffic light, 1 stop sign, 46.7ms\n",
      "Speed: 2.2ms preprocess, 46.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 1 car, 1 stop sign, 47.9ms\n",
      "Speed: 1.7ms preprocess, 47.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bicycle, 2 cars, 1 stop sign, 47.3ms\n",
      "Speed: 4.0ms preprocess, 47.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Video saved with annotations.\n",
      "\n",
      " Scene description generated by LLM:\n",
      "\n",
      "The scene is a bustling city intersection with multiple traffic lights controlling the flow of traffic. There are numerous people walking around, some of them riding bicycles. Cars are driving through the intersection, and there are a few stop signs in the vicinity. Overall, it appears to be a busy and active urban area with a mix of pedestrians, cyclists, and vehicles.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLOWorld\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='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')\n",
    "\n",
    "def detect_objects(video_path, output_path, weight_file='yolov8x-worldv2.pt', classes=None, frame_skip=5, confidence_threshold=0.6):\n",
    "    model = YOLOWorld(weight_file)\n",
    "\n",
    "    if classes is not None:\n",
    "        model.set_classes(classes)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open video\")\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps // frame_skip, (width, height))\n",
    "\n",
    "    frame_id = 0\n",
    "    all_detections = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "        if frame_id % frame_skip != 0:\n",
    "            continue\n",
    "\n",
    "        results = model.predict(frame)\n",
    "        boxes = results[0].boxes\n",
    "        predictions = boxes.data.cpu().numpy()\n",
    "\n",
    "        for pred in predictions:\n",
    "            x1, y1, x2, y2, score, class_id = pred[0], pred[1], pred[2], pred[3], pred[4], int(pred[5])\n",
    "\n",
    "            if score < confidence_threshold:\n",
    "                continue\n",
    "\n",
    "            label = f\"{model.names[class_id]}\"\n",
    "            all_detections.append(label)\n",
    "\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(f\"{label} {score:.2f}\", cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            cv2.rectangle(frame, (int(x1), int(y1) - text_height - baseline), (int(x1) + text_width, int(y1)), color, -1)\n",
    "            cv2.putText(frame, f\"{label} {score:.2f}\", (int(x1), int(y1) - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    return all_detections\n",
    "\n",
    "def summarize_with_llm(detections):\n",
    "\n",
    "    objects_summary = {}\n",
    "    for obj in detections:\n",
    "        if obj in objects_summary:\n",
    "            objects_summary[obj] += 1\n",
    "        else:\n",
    "            objects_summary[obj] = 1\n",
    "\n",
    "    summary_text = \"Detected objects: \" + \", \".join([f\"{count} {obj}(s)\" for obj, count in objects_summary.items()])\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant that describes video scenes based on object detections.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Based on the following detections, write a short natural language description of the scene: {summary_text}\"}\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    description = response.choices[0].message.content\n",
    "    return description\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    video_file = r\"C:\\Users\\tyler\\OneDrive\\Desktop\\Computer Vision\\CV Project\\Videos\\walkog.mp4\"\n",
    "    output_video_file = r\"C:\\Users\\tyler\\OneDrive\\Desktop\\Computer Vision\\CV Project\\Videos\\LLM_walk_2.mp4\"\n",
    "\n",
    "    walking_hazards = [\n",
    "        'person', 'bicycle', 'car', 'motorcycle', 'bus', 'truck', 'traffic light', 'stop sign'\n",
    "    ]\n",
    "\n",
    "    detections = detect_objects(video_file, output_video_file, classes=walking_hazards)\n",
    "    print(\" Video saved with annotations.\")\n",
    "\n",
    "    description = summarize_with_llm(detections)\n",
    "    print(\"\\n Scene description generated by LLM:\\n\")\n",
    "    print(description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs real-time object detection and generates scene descriptions approximately every 60 seconds.\n",
    "It also implements custom warning generation based on detected changes in the environment.\n",
    "Warnings are printed immediately when new objects appear or disappear, improving navigation assistance.\n",
    "The warning system was adapted manually and could be further improved with more precise anomaly detection logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T06:47:40.349781Z",
     "start_time": "2025-04-29T06:43:32.482194Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msk-proj-3uHr6XdQ25JrMnINxEM6hfcdTRQPwNwu_GksxPFVKPcuKwUbhCabfhdcdfkeFzOe5nGFmugRHhT3BlbkFJyHKF6o9AfjdpsPjb70Dr7BdE_mnB6HSV2Wnk_Tum8tk9zM6hRjHo2gCqVl36JduVQtejVwHaEA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetect_objects_in_frame\u001b[39m(model, frame, confidence_threshold=\u001b[32m0.6\u001b[39m):\n\u001b[32m     11\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Detect objects in a single frame using YOLO-World.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_client.py:136\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    134\u001b[39m     base_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[38;5;28mself\u001b[39m._default_stream_cls = Stream\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m.completions = completions.Completions(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:854\u001b[39m, in \u001b[36mSyncAPIClient.__init__\u001b[39m\u001b[34m(self, version, base_url, max_retries, timeout, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[39m\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    841\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid `http_client` argument; Expected an instance of `httpx.Client` but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(http_client)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    842\u001b[39m     )\n\u001b[32m    844\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    845\u001b[39m     version=version,\n\u001b[32m    846\u001b[39m     \u001b[38;5;66;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    852\u001b[39m     _strict_response_validation=_strict_response_validation,\n\u001b[32m    853\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m \u001b[38;5;28mself\u001b[39m._client = http_client \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mSyncHttpxClientWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;49;00m\n\u001b[32m    857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:784\u001b[39m, in \u001b[36m_DefaultHttpxClient.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    782\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mlimits\u001b[39m\u001b[33m\"\u001b[39m, DEFAULT_CONNECTION_LIMITS)\n\u001b[32m    783\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mfollow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:688\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, auth, params, headers, cookies, verify, cert, trust_env, http1, http2, proxy, mounts, timeout, follow_redirects, limits, max_redirects, event_hooks, base_url, transport, default_encoding)\u001b[39m\n\u001b[32m    685\u001b[39m allow_env_proxies = trust_env \u001b[38;5;129;01mand\u001b[39;00m transport \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    686\u001b[39m proxy_map = \u001b[38;5;28mself\u001b[39m._get_proxy_map(proxy, allow_env_proxies)\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m \u001b[38;5;28mself\u001b[39m._transport = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_transport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28mself\u001b[39m._mounts: \u001b[38;5;28mdict\u001b[39m[URLPattern, BaseTransport | \u001b[38;5;28;01mNone\u001b[39;00m] = {\n\u001b[32m    698\u001b[39m     URLPattern(key): \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, proxy \u001b[38;5;129;01min\u001b[39;00m proxy_map.items()\n\u001b[32m    710\u001b[39m }\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mounts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:731\u001b[39m, in \u001b[36mClient._init_transport\u001b[39m\u001b[34m(self, verify, cert, trust_env, http1, http2, limits, transport)\u001b[39m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transport \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    729\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m transport\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHTTPTransport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:153\u001b[39m, in \u001b[36mHTTPTransport.__init__\u001b[39m\u001b[34m(self, verify, cert, trust_env, http1, http2, limits, proxy, uds, local_address, retries, socket_options)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    152\u001b[39m proxy = Proxy(url=proxy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(proxy, (\u001b[38;5;28mstr\u001b[39m, URL)) \u001b[38;5;28;01melse\u001b[39;00m proxy\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m ssl_context = \u001b[43mcreate_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = httpcore.ConnectionPool(\n\u001b[32m    157\u001b[39m         ssl_context=ssl_context,\n\u001b[32m    158\u001b[39m         max_connections=limits.max_connections,\n\u001b[32m   (...)\u001b[39m\u001b[32m    166\u001b[39m         socket_options=socket_options,\n\u001b[32m    167\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_config.py:40\u001b[39m, in \u001b[36mcreate_ssl_context\u001b[39m\u001b[34m(verify, cert, trust_env)\u001b[39m\n\u001b[32m     37\u001b[39m         ctx = ssl.create_default_context(capath=os.environ[\u001b[33m\"\u001b[39m\u001b[33mSSL_CERT_DIR\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;66;03m# Default case...\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         ctx = \u001b[43mssl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_default_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcafile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcertifi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m verify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m     42\u001b[39m     ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:708\u001b[39m, in \u001b[36mcreate_default_context\u001b[39m\u001b[34m(purpose, cafile, capath, cadata)\u001b[39m\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(purpose)\n\u001b[32m    707\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cafile \u001b[38;5;129;01mor\u001b[39;00m capath \u001b[38;5;129;01mor\u001b[39;00m cadata:\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m     \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_verify_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcafile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m context.verify_mode != CERT_NONE:\n\u001b[32m    710\u001b[39m     \u001b[38;5;66;03m# no explicit cafile, capath or cadata but the verify mode is\u001b[39;00m\n\u001b[32m    711\u001b[39m     \u001b[38;5;66;03m# CERT_OPTIONAL or CERT_REQUIRED. Let's try to load default system\u001b[39;00m\n\u001b[32m    712\u001b[39m     \u001b[38;5;66;03m# root CA certificates for the given purpose. This may fail silently.\u001b[39;00m\n\u001b[32m    713\u001b[39m     context.load_default_certs(purpose)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLOWorld\n",
    "import numpy as np\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "\n",
    "\n",
    "def detect_objects_in_frame(model, frame, confidence_threshold=0.6):\n",
    "    \"\"\"Detect objects in a single frame using YOLO-World.\"\"\"\n",
    "    results = model.predict(frame)\n",
    "    boxes = results[0].boxes\n",
    "    predictions = boxes.data.cpu().numpy()\n",
    "\n",
    "    detected_objects = []\n",
    "    for pred in predictions:\n",
    "        score, class_id = pred[4], int(pred[5])\n",
    "        if score >= confidence_threshold:\n",
    "            detected_objects.append(model.names[class_id])\n",
    "\n",
    "    return detected_objects\n",
    "\n",
    "def summarize_with_llm(objects, mode=\"description\"):\n",
    "    \"\"\"Summarize detected objects using OpenAI's LLM.\"\"\"\n",
    "    if not objects:\n",
    "        return None\n",
    "\n",
    "    objects_summary = {}\n",
    "    for obj in objects:\n",
    "        objects_summary[obj] = objects_summary.get(obj, 0) + 1\n",
    "\n",
    "    text_summary = \", \".join([f\"{count} {obj}(s)\" for obj, count in objects_summary.items()])\n",
    "\n",
    "    if mode == \"description\":\n",
    "        prompt = f\"Describe the following environment in natural language: {text_summary}\"\n",
    "    elif mode == \"warning\":\n",
    "        prompt = f\"Based on the following objects, generate a short warning message if there is any obstacle: {text_summary}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant that helps with real-time navigation for visually impaired users.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def initialize_model_and_video(video_file, output_video_file, weight_file, walking_hazards, frame_skip):\n",
    "    model = YOLOWorld(weight_file)\n",
    "    model.set_classes(walking_hazards)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open video\")\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_file, fourcc, fps // frame_skip, (width, height))\n",
    "\n",
    "    return model, cap, out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    video_file = r\"C:\\Users\\tyler\\OneDrive\\Desktop\\Computer Vision\\CV Project\\Videos\\walkog.mp4\"\n",
    "    output_video_file = r\"C:\\Users\\tyler\\OneDrive\\Desktop\\Computer Vision\\CV Project\\Videos\\LLM_walk_3.mp4\"\n",
    "    weight_file = 'yolov8x-worldv2.pt'\n",
    "    frame_skip = 5\n",
    "    confidence_threshold = 0.6\n",
    "    describe_interval = 30  # seconds between descriptions\n",
    "    \n",
    "    detections = detect_objects(video_file, output_video_file, classes=walking_hazards)\n",
    "    description = summarize_with_llm(detections)\n",
    "    print(\"\\n Scene description generated by LLM:\\n\")\n",
    "    print(description)\n",
    "\n",
    "    # Classes to detect\n",
    "    walking_hazards = [\n",
    "        'car', 'person', 'bus', 'bicycle', 'motorcycle', 'traffic light', 'stop sign',\n",
    "        'fountain', 'traffic red light', 'traffic green light'\n",
    "        'crosswalk', 'sidewalk', 'door', 'stair', 'escalator', 'elevator', 'ramp',\n",
    "        'bench', 'trash can', 'pole', 'fence', 'tree', 'dog', 'cat', 'bird', 'parking meter',\n",
    "        'mailbox', 'manhole', 'puddle', 'construction sign', 'construction barrier',\n",
    "        'scaffolding', 'hole', 'crack', 'speed bump', 'curb', 'guardrail', 'traffic cone',\n",
    "        'traffic barrel', 'pedestrian signal', 'street sign', 'fire hydrant', 'lamp post',\n",
    "        'bench', 'picnic table', 'public restroom', 'fountain', 'statue', 'monument',\n",
    "        'directional sign', 'information sign', 'map', 'emergency exit', 'no smoking sign',\n",
    "        'wet floor sign', 'closed sign', 'open sign', 'entrance sign', 'exit sign',\n",
    "        'stairs sign', 'escalator sign', 'elevator sign', 'restroom sign', 'men restroom sign',\n",
    "        'women restroom sign', 'unisex restroom sign', 'baby changing station',\n",
    "        'wheelchair accessible sign', 'braille sign', 'audio signal device', 'tactile paving',\n",
    "        'detectable warning surface', 'guide rail', 'handrail', 'turnstile', 'gate',\n",
    "        'ticket barrier', 'security checkpoint', 'metal detector', 'baggage claim',\n",
    "        'lost and found', 'information desk', 'meeting point', 'waiting area', 'seating area',\n",
    "        'boarding area', 'disembarking area', 'charging station', 'water dispenser',\n",
    "        'vending machine', 'ATM', 'kiosk', 'public telephone', 'public Wi-Fi hotspot',\n",
    "        'emergency phone', 'first aid station', 'defibrillator',\n",
    "        'tree', 'pole', 'lamp post', 'staff', 'road hazard'\n",
    "    ]\n",
    "\n",
    "    # Load YOLO-World model\n",
    "    model = YOLOWorld(weight_file)\n",
    "    model.set_classes(walking_hazards)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open video\")\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_file, fourcc, fps // frame_skip, (width, height))\n",
    "\n",
    "    frame_id = 0\n",
    "    last_description_time = None\n",
    "    last_detected_objects = set()\n",
    "    last_warning_text = \"\"\n",
    "\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        initial_objects = detect_objects_in_frame(model, frame, confidence_threshold)\n",
    "        description = summarize_with_llm(initial_objects, mode=\"description\")\n",
    "        if description:\n",
    "            print(f\" Initial Description: {description}\")\n",
    "        last_description_time = time.time()\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "        if frame_id % frame_skip != 0:\n",
    "            continue\n",
    "        \n",
    "        current_objects = detect_objects_in_frame(model, frame, confidence_threshold)\n",
    "        current_object_set = set(current_objects)\n",
    "        detections = detect_objects(video_file, output_video_file, classes=walking_hazards)\n",
    "        description = summarize_with_llm(detections)\n",
    "        print(\"\\n Scene description generated by LLM:\\n\")\n",
    "        print(description)\n",
    "\n",
    "        # Draw detections\n",
    "        y_offset = 30\n",
    "        for obj in current_objects:\n",
    "            cv2.putText(frame, obj, (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            y_offset += 30\n",
    "\n",
    "        # Description every 60 seconds\n",
    "        if time.time() - last_description_time >= describe_interval:\n",
    "            description = summarize_with_llm(current_objects, mode=\"description\")\n",
    "            if description:\n",
    "                print(f\" Description: {description}\")\n",
    "            last_description_time = time.time()\n",
    "\n",
    "        # Warning if object set changes\n",
    "        if current_object_set != last_detected_objects:\n",
    "            warning = summarize_with_llm(current_objects, mode=\"warning\")\n",
    "            if warning and warning != last_warning_text:\n",
    "                print(f\" Warning: {warning}\")\n",
    "                last_warning_text = warning\n",
    "            last_detected_objects = current_object_set\n",
    "        \n",
    "        \n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\" Video processing completed.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
